---
title: Quick start
engine: knitr
---

Depends on what you want to do:

* Analyse the results?
* Run a pipeline?
* Contribute methods?


## Previous documentation


The `src/` folder contains modular software components for running a modality alignment benchmark. Running the full pipeline is quite easy.

**Step 0, fetch viash and nextflow:** run the `bin/init` executable.

```bash
bin/init
```

    > Using tag develop
    > Cleanup
    > Downloading Viash source code @develop
    > Building Viash from source
    > Building Viash helper scripts from source
    > Done, happy viash-ing!

**Step 1, download test resources:** by running the following command.

```bash
bin/viash run src/common/sync_test_resources/config.vsh.yaml
```

    Completed 256.0 KiB/7.2 MiB (302.6 KiB/s) with 6 file(s) remaining
    Completed 512.0 KiB/7.2 MiB (595.8 KiB/s) with 6 file(s) remaining
    Completed 768.0 KiB/7.2 MiB (880.3 KiB/s) with 6 file(s) remaining
    Completed 1.0 MiB/7.2 MiB (1.1 MiB/s) with 6 file(s) remaining    
    Completed 1.2 MiB/7.2 MiB (1.3 MiB/s) with 6 file(s) remaining
    ...

**Step 2, build all the components:** in the `src/` folder as standalone executables in the `target/` folder. Use the `-q 'xxx'` parameter to build a subset of components in the repository.

```bash
bin/viash_build -q 'label_projection|common'
```

    In development mode with 'dev'.
    Exporting split_dataset (label_projection) =docker=> target/docker/label_projection/split_dataset
    Exporting accuracy (label_projection/metrics) =docker=> target/docker/label_projection/metrics/accuracy
    Exporting random_labels (label_projection/control_methods) =docker=> target/docker/label_projection/control_methods/random_labels
    [notice] Building container 'label_projection/control_methods_random_labels:dev' with Dockerfile
    [notice] Building container 'common/data_processing_dataset_concatenate:dev' with Dockerfile
    [notice] Building container 'label_projection/metrics_accuracy:dev' with Dockerfile
    ...

These standalone executables you can give to somebody else, and they will be able to run it, provided that they have Bash and Docker installed.
The command might take a while to run, since it is building a docker container for each of the components. 

**Step 3, run the pipeline with nextflow.** To do so, run the bash script located at `src/label_projection/workflows/run_nextflow.sh`:

```bash
src/label_projection/workflows/run/run_test.sh
```

    N E X T F L O W  ~  version 22.04.5
    Launching `src/label_projection/workflows/run/main.nf` [small_becquerel] DSL2 - revision: ece87259df
    executor >  local (19)
    [39/e1bb01] process > run_wf:true_labels:true_labels_process (1)                 [100%] 1 of 1 ✔
    [3b/d41f8a] process > run_wf:random_labels:random_labels_process (1)             [100%] 1 of 1 ✔
    [c2/0398dd] process > run_wf:majority_vote:majority_vote_process (1)             [100%] 1 of 1 ✔
    [fd/92edc7] process > run_wf:knn:knn_process (1)           [100%] 1 of 1 ✔
    [f7/7cdb34] process > run_wf:logistic_regression:logistic_regression_process (1) [100%] 1 of 1 ✔
    [4f/6a67e4] process > run_wf:mlp:mlp_process (1)                                 [100%] 1 of 1 ✔
    [a5/ae6341] process > run_wf:accuracy:accuracy_process (6)                       [100%] 6 of 6 ✔
    [72/5076e8] process > run_wf:f1:f1_process (6)                                   [100%] 6 of 6 ✔
    [cf/eccd48] process > run_wf:extract_scores:extract_scores_process               [100%] 1 of 1 ✔
